{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Matrix Demo\n",
    "In this notebook, some Matrix operations are done and shows agreement in forward/backward passes with PyTorch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from matprop.engine import Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Matrix(\ndata=\n[[1. 2.]\n [2. 1.]]\ngrad=\n[[0. 0.]\n [0. 0.]]\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = Matrix([[1, 2], [2, 1]])\n",
    "m2 = Matrix([[2, 1], [1, 2]])\n",
    "m1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Matrix(\ndata=\n[[3. 3.]\n [3. 3.]]\ngrad=\n[[0. 0.]\n [0. 0.]]\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = m1 + m2\n",
    "m3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{Matrix(\n data=\n [[1. 2.]\n  [2. 1.]]\n grad=\n [[0. 0.]\n  [0. 0.]]\n ),\n Matrix(\n data=\n [[2. 1.]\n  [1. 2.]]\n grad=\n [[0. 0.]\n  [0. 0.]]\n )}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3._prev"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(407., grad_fn=<SumBackward0>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[1., 2.]])\n",
    "A.requires_grad = True\n",
    "\n",
    "B = torch.Tensor([[3., 2.],\n",
    "                  [2., 1.]])\n",
    "B.requires_grad = True\n",
    "\n",
    "AB = A @ B\n",
    "AB.retain_grad()\n",
    "\n",
    "AB2 = AB ** 3\n",
    "AB2.retain_grad()\n",
    "\n",
    "Relu = AB2.relu()\n",
    "Relu.retain_grad()\n",
    "\n",
    "Sum = Relu.sum()\n",
    "Sum.retain_grad()\n",
    "\n",
    "Sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[537., 342.]]),\n tensor([[147.,  48.],\n         [294.,  96.]]),\n tensor([[147.,  48.]]),\n tensor([[1., 1.]]),\n tensor([[1., 1.]]),\n tensor(1.))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum.backward(retain_graph=True)\n",
    "A.grad, B.grad, AB.grad, AB2.grad, Relu.grad, Sum.grad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Matrix(\ndata=\n407.0\ngrad=\n0.0\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Matrix([[1., 2.]])\n",
    "\n",
    "B = Matrix([[3., 2.],\n",
    "            [2., 1.]])\n",
    "\n",
    "AB = A @ B\n",
    "\n",
    "AB2 = AB ** 3\n",
    "\n",
    "Relu = AB2.relu()\n",
    "\n",
    "Sum = Relu.sum()\n",
    "\n",
    "Sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[537., 342.]], dtype=float32),\n array([[147.,  48.],\n        [294.,  96.]], dtype=float32),\n array([[147.,  48.]], dtype=float32),\n array([[1., 1.]], dtype=float32),\n array([[1., 1.]], dtype=float32),\n array([[1.]]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum.backward()\n",
    "A.grad, B.grad, AB.grad, AB2.grad, Relu.grad, Sum.grad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(13., grad_fn=<SumBackward0>)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[1.],\n",
    "                  [2.]])\n",
    "A.requires_grad = True\n",
    "\n",
    "AT = A.T\n",
    "AT.retain_grad()\n",
    "\n",
    "B = torch.Tensor([[3., 2.],\n",
    "                  [2., 1.]])\n",
    "B.requires_grad = True\n",
    "\n",
    "AB = AT @ B\n",
    "AB.retain_grad()\n",
    "\n",
    "C = torch.tensor([[1., 1.]])\n",
    "C.requires_grad = True\n",
    "\n",
    "ABPlusC = AB + C\n",
    "ABPlusC.retain_grad()\n",
    "\n",
    "Sum = ABPlusC.sum()\n",
    "Sum.retain_grad()\n",
    "\n",
    "Sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[5.],\n         [3.]]),\n tensor([[5., 3.]]),\n tensor([[1., 1.],\n         [2., 2.]]),\n tensor([[1., 1.]]),\n tensor([[1., 1.]]),\n tensor(1.))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum.backward(retain_graph=True)\n",
    "A.grad, AT.grad, B.grad, AB.grad, ABPlusC.grad, Sum.grad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Matrix(\ndata=\n13.0\ngrad=\n0.0\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Matrix([[1.],\n",
    "            [2.]])\n",
    "\n",
    "AT = A.transpose()\n",
    "\n",
    "B = Matrix([[3., 2.],\n",
    "            [2., 1.]])\n",
    "\n",
    "AB = AT @ B\n",
    "\n",
    "C = Matrix([[1., 1.]])\n",
    "\n",
    "ABPlusC = AB + C\n",
    "\n",
    "Sum = ABPlusC.sum()\n",
    "\n",
    "Sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[5.],\n        [3.]], dtype=float32),\n array([[5., 3.]], dtype=float32),\n array([[1., 1.],\n        [2., 2.]], dtype=float32),\n array([[1., 1.]], dtype=float32),\n array([[1., 1.]], dtype=float32),\n array([[1.]]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum.backward()\n",
    "A.grad, AT.grad, B.grad, AB.grad, ABPlusC.grad, Sum.grad"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
